# -*- coding: utf-8 -*-
"""User interaction/events Project .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hiWrTTOX1tL4miwNGa5vSF96BoSwGFZC

# User interaction/events

# Data = source from an app or system usage log from a user

# ‚úÖ Step-by-Step Project Pipeline:
1. Define the Problem/Goal
* Ask: What do you want to learn or predict?
Examples:

* Are you trying to predict app crashes?

* Analyze user behavior patterns?

* Understand network usage trends?

* Recommend updates for apps?

* Example Objective: "Identify the patterns that lead to app crashes."

# üîÆ 1. Predict App Update Outcome (Supervised ML)
- Target: Update Status
Use the other features (App Name, Event Type, Time, Network Type, etc.) to predict whether an update will be a "Success", "Failed", or "Not Checked".

- ‚úÖ Great for classification models like Logistic Regression, Random Forest, or XGBoost.

# üß† 2. Usage Pattern Insights (Descriptive + Clustering)
* What time of day users open apps most?

* Which apps are frequently updated?

* Do certain networks (e.g., 5G vs. Wi-Fi) lead to better update success?

* Use clustering (KMeans) to group similar usage behavior ‚Äî e.g., people who mostly open social apps late at night on 5G.

# ‚è±Ô∏è 3. Time-Based Trends
- Are updates more likely at night or day?

- Does the failure rate of updates increase on certain network types?

- Visualize trends like:

- App installs over time.

- Update success/failure over days or hours.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import xgboost as xgb

df= pd.read_csv("/Users/apple/Downloads/Data_science_file/Krish_naik_Files_notes/Projects/All_Projects/User_interaction_events/meta_app_manager_large_dataset.csv")

df

"""‚Ä¢ üîç Columns:
* Timestamp ‚Äì When the event occurred.

* App Name ‚Äì Which app the event is related to.

* Event Type ‚Äì Type of action/event (e.g., install, open, crash).

* Device Model ‚Äì The model of the user's device.

* OS Version ‚Äì The operating system version.

* Network Type ‚Äì Wi-Fi, 4G, 5G, etc.

* Update Status ‚Äì Whether the app is updated or not.

# Data Cleaning & Preprocessing
‚úÖ Common tasks:

Handle missing/null values
"""

df.info()

df.describe().T

df.isnull().sum()

df.duplicated().sum()

#  Drop in Place (Without Reassignment):
df.drop_duplicates(inplace=True)

df.duplicated().sum()

"""- Convert Timestamp into features (e.g., hour, day, weekday)"""

# Convert Timestamp
df['Timestamp'] = pd.to_datetime(df['Timestamp'])

# Feature engineering
df['Hour'] = df['Timestamp'].dt.hour
df['DayOfWeek'] = df['Timestamp'].dt.day_name()

"""# üìä STEP 1: EDA & Feature Engineering"""

# Quick EDA
print(df['Update Status'].value_counts())

df['Event Type'].value_counts()

"""# Exploratory Data Analysis (EDA)
üìä Visualize to get insights:


Crashes by device model

Event frequency over time

Network types vs. update status


"""

# Plot: Update Status distribution
sns.countplot(data=df, x='Update Status')
plt.title("Update Status Distribution")
plt.xlabel("Update Status")
plt.ylabel("No of Users (Counts)")
plt.show()

# Plot: App usage by hour
plt.figure(figsize=(16, 6))
sns.countplot(data=df, x='Hour', hue='Event Type')
plt.title("App Events by Hour of Day")
plt.show()

# Plot: Network Type vs Update Status
plt.figure(figsize=(8, 5))
sns.countplot(data=df, x='Network Type', hue='Update Status')
plt.title("Network Type vs Update Success")
plt.show()



"""# üéØ STEP 2: Modeling ‚Äì Predict Update Status
Encode categorical features:
"""

features = ['App Name', 'Event Type', 'Device Model', 'OS Version', 'Network Type', 'Hour', 'DayOfWeek']
target = 'Update Status'

# Encode categorical features
df_encoded = df[features + [target]].copy()
for col in df_encoded.columns:
    if df_encoded[col].dtype == 'object':
        df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col])

"""## Train/test split + model:"""

X = df_encoded.drop('Update Status', axis=1)
y = df_encoded['Update Status']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print(confusion_matrix(y_test, y_pred))

print(classification_report(y_test, y_pred))

"""## ü§ñ STEP 3: Clustering
- Let‚Äôs group similar behavior patterns:
"""

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# Select features (excluding target)
cluster_data = df_encoded.drop(columns=['Update Status'])

# Normalize
scaler = StandardScaler()
scaled = scaler.fit_transform(cluster_data)

# KMeans
kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(scaled)

df['Cluster'] = clusters

# Visualize clusters vs event types
sns.countplot(data=df, x='Cluster', hue='Event Type')
plt.title("Cluster-wise Event Type Distribution")
plt.show()

"""# üß™ STEP 4: Time Series
- Aggregating events over time to see patterns:
"""

# Daily count of events
df['Date'] = df['Timestamp'].dt.date
daily_events = df.groupby(['Date', 'Event Type']).size().unstack().fillna(0)

daily_events.plot(kind='line', figsize=(12, 6), title='Daily App Events Over Time')
plt.ylabel("Event Count")
plt.show()

"""# üõ†Ô∏è 4. Build a Dashboard
- create a Streamlit or Tableau dashboard to monitor:

- Which apps are updated most often

- Network performance

- Most active time for app interactions

## üßë‚Äçüíª STEP 5: Streamlit Dashboard
- Basic layout:

## ‚úÖ DONE!
You now have:

Feature-rich dataset ‚úÖ

EDA + visualizations ‚úÖ

A classifier model ‚úÖ

Clustering insights ‚úÖ

Time series analysis ‚úÖ

Option to deploy dashboard ‚úÖ

# 5. Feature Engineering
Create new features that might help:

üìå Ideas:

Time since last update

Device popularity

Whether user is on mobile data vs Wi-Fi

OS version groupings (e.g., major versions)
"""



"""# 6. Model Building (if predictive task)
If your goal involves prediction (e.g., will app crash happen?), you can go for:

Classification: Logistic Regression, Random Forest, XGBoost

Clustering (if you're segmenting users or devices): K-Means

Time Series Analysis (for trends): ARIMA, Prophet

Split your data into train/test or use cross-validation.
"""



"""#  7. Model Evaluation
Based on task:

Accuracy, Precision, Recall, F1 for classification

Silhouette Score for clustering

RMSE, MAE for regression

Use confusion matrix, ROC curve, feature importance plots, etc.
"""



"""# 8. Insights & Reporting
Summarize your findings:

Key factors causing crashes?

Peak hours of usage?

Devices that are more error-prone?

Visual dashboards: Power BI, Tableau, or even plotly Dash.
"""



"""# 9. Deployment (Optional)
If you want to put the model in production:

Use Flask/FastAPI for API

Store model with joblib/pickle

Monitor performance over time
"""



"""# 10. Documentation & Next Steps
Keep a well-documented Jupyter Notebook or script

Write clear README if it's a GitHub project

Think about data drift or adding new features later
"""

